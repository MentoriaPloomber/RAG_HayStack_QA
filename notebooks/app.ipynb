{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "zsh:1: no matches found: farm-haystack[colab,inference,faiss]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: openai in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: torch in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: pandas in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: numpy in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (1.25.2)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: scikit-learn in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: tqdm in /Users/anuarmenconemes/opt/anaconda3/envs/hacktoberfest-env/lib/python3.10/site-packages (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "#Instala los paquetes necesarios\n",
    "#%%bash\n",
    "!pip install farm-haystack[colab,inference,faiss]\n",
    "!pip install openai\n",
    "\n",
    "# Otros paquetes que pueden ser necesarios\n",
    "!pip install torch\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8262615d3b04f468a25d0c0ce98f027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: Sí, la diversidad sexual se protege en las tutelas. Los textos mencionan varios casos en los que las tutelas se han utilizado para defender los derechos sexuales y reproductivos, la igualdad, la no discriminación, el libre desarrollo de la personalidad, y la dignidad humana. Esto incluye casos de hombres que tienen relaciones sexuales con hombres, y personas con identidades de género diversas.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from haystack import Pipeline\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.nodes import EmbeddingRetriever, PromptNode, PromptTemplate, AnswerParser\n",
    "\n",
    "# Importa la clave de API desde config.py\n",
    "#openai_api_key = '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' \n",
    "\n",
    "# Importa la clave de API desde config.py\n",
    "from config_api import openai_api_key \n",
    "\n",
    "# Carga la base de datos\n",
    "if os.path.exists(\"my_index.faiss\"):\n",
    "    document_store = FAISSDocumentStore.load(index_path=\"my_index.faiss\", config_path=\"my_config.json\")\n",
    "else:\n",
    "    print(\"La base de datos no se ha cargado. Debes ejecutar la función 'index_documents' primero.\")\n",
    "\n",
    "rag_prompt = PromptTemplate(\n",
    "    prompt=\"\"\"Synthesize a comprehensive answer from the following text for the given question.\n",
    "                             Provide a clear and concise response that summarizes the key points and information presented in the text.\n",
    "                             Your answer should be in your own words and be no longer than 50 words.\n",
    "                             \\n\\n Related text: {join(documents)} \\n\\n Question: {query} \\n\\n Answer:\"\"\",\n",
    "    output_parser=AnswerParser(),\n",
    ")\n",
    "\n",
    "model = \"gpt-4\"\n",
    "prompt_node = PromptNode(\n",
    "    model_name_or_path=model,\n",
    "    api_key=openai_api_key,\n",
    "    default_prompt_template=rag_prompt\n",
    ")\n",
    "\n",
    "retriever = EmbeddingRetriever(document_store=document_store,\n",
    "                               embedding_model=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "query_pipeline = Pipeline()\n",
    "query_pipeline.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "query_pipeline.add_node(component=prompt_node, name=\"PromptNode\", inputs=[\"Retriever\"])\n",
    "\n",
    "def answer_question(question):\n",
    "    respuesta = query_pipeline.run(query=question)\n",
    "    return respuesta['answers'][0].to_dict()['answer']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_question = input(\"Haz una pregunta (o escribe 'salir' para salir): \")\n",
    "        if user_question.lower() == 'salir':\n",
    "            break\n",
    "        answer = answer_question(user_question)\n",
    "        print(\"Respuesta:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hacktoberfest-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
